{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                ENSMUSG00000033845_Mrpl15\n",
      "2                ENSMUSG00000025903_Lypla1\n",
      "3                 ENSMUSG00000033813_Tcea1\n",
      "4                 ENSMUSG00000002459_Rgs20\n",
      "5               ENSMUSG00000033793_Atp6v1h\n",
      "                       ...                \n",
      "17771        ENSMUSG00000094799_AC125149.4\n",
      "17772        ENSMUSG00000079808_AC168977.1\n",
      "17773              ENSMUSG00000095041_PISD\n",
      "17774             ENSMUSG00000063897_DHRSX\n",
      "17775    ENSMUSG00000095742_CAAA01147332.1\n",
      "Name: gene_name, Length: 17775, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import scanpy as sc\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = \"extracted_data/GSM2396856_dc_3hr_genenames.csv.gz\"\n",
    "\n",
    "genes = pd.read_csv(path, header=None)\n",
    "genes.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "genes = genes.iloc[1:]\n",
    "gene_names = genes[\"gene_name\"]\n",
    "print(gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m cells_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cellnames.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Load sparse gene expression matrix\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmmread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmtx_file\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtocsc()  \u001b[38;5;66;03m# Convert to Compressed Sparse Column format\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Load gene names\u001b[39;00m\n\u001b[0;32m     36\u001b[0m genes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(genes_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\nlp\\Lib\\site-packages\\scipy\\io\\_fast_matrix_market\\__init__.py:363\u001b[0m, in \u001b[0;36mmmread\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coo_matrix\n\u001b[1;32m--> 363\u001b[0m     triplet, shape \u001b[38;5;241m=\u001b[39m \u001b[43m_read_body_coo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneralize_symmetry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_to_close:\n\u001b[0;32m    365\u001b[0m         stream_to_close\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\nlp\\Lib\\site-packages\\scipy\\io\\_fast_matrix_market\\__init__.py:149\u001b[0m, in \u001b[0;36m_read_body_coo\u001b[1;34m(cursor, generalize_symmetry)\u001b[0m\n\u001b[0;32m    146\u001b[0m j \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(cursor\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39mindex_dtype)\n\u001b[0;32m    147\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(cursor\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39m_field_to_dtype\u001b[38;5;241m.\u001b[39mget(cursor\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mfield))\n\u001b[1;32m--> 149\u001b[0m \u001b[43m_fmm_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_body_coo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generalize_symmetry \u001b[38;5;129;01mand\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39msymmetry \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    152\u001b[0m     off_diagonal_mask \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;241m!=\u001b[39m j)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\nlp\\Lib\\gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread(size)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\nlp\\Lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\nlp\\Lib\\gzip.py:507\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    505\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 507\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scanpy as sc\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data_folder = \"extracted_data/\"\n",
    "output_folder = \"converted_data/\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"Created directory: {output_folder}\")\n",
    "\n",
    "mtx_files = glob.glob(os.path.join(data_folder, \"*.mtx.txt.gz\"))\n",
    "\n",
    "for mtx_file in mtx_files:\n",
    "    try:\n",
    "       \n",
    "        base_name = os.path.basename(mtx_file).split(\".mtx\")[0]\n",
    "\n",
    "     \n",
    "        genes_path = os.path.join(data_folder, f\"{base_name}_genenames.csv.gz\")\n",
    "        cells_path = os.path.join(data_folder, f\"{base_name}_cellnames.csv.gz\")\n",
    "\n",
    "        matrix = scipy.io.mmread(mtx_file).tocsc()  \n",
    "\n",
    "        # Load gene names\n",
    "        genes = pd.read_csv(genes_path, header=None)\n",
    "        genes.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "\n",
    "        # Load cell barcodes\n",
    "        cells = pd.read_csv(cells_path, header=None)\n",
    "        cells.rename(columns={0: \"cell_barcode\"}, inplace=True)\n",
    "\n",
    "        # Ensure gene count matches matrix rows\n",
    "        if genes.shape[0] != matrix.shape[0]:\n",
    "            genes = genes.iloc[:matrix.shape[0]]  \n",
    "\n",
    "        # Convert to AnnData format\n",
    "        adata = sc.AnnData(X=matrix.T)  \n",
    "        adata.var[\"gene_name\"] = genes[\"gene_name\"].values  \n",
    "        adata.obs[\"cell_barcode\"] = cells[\"cell_barcode\"].values  \n",
    "        # Save to h5ad format\n",
    "        h5ad_path = os.path.join(output_folder, f\"{base_name}.h5ad\")\n",
    "        adata.write(h5ad_path)\n",
    "        print(f\"Saved h5ad file: {h5ad_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {mtx_file}: {e}\")\n",
    "\n",
    "print(\"All datasets processed successfully!\")\n",
    "\n",
    "# Load one h5ad file for visualization\n",
    "h5ad_file = glob.glob(os.path.join(output_folder, \"*.h5ad\"))[0]  \n",
    "\n",
    "# Check basic dataset information\n",
    "print(adata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extracted_data\\\\GSM2396856_dc_3hr.mtx.txt.gz',\n",
       " 'extracted_data\\\\GSM2396857_dc_0hr.mtx.txt.gz',\n",
       " 'extracted_data\\\\GSM2396858_k562_tfs_7.mtx.txt.gz',\n",
       " 'extracted_data\\\\GSM2396859_k562_tfs_13.mtx.txt.gz',\n",
       " 'extracted_data\\\\GSM2396860_k562_tfs_highmoi.mtx.txt.gz',\n",
       " 'extracted_data\\\\GSM2396861_k562_ccycle.mtx.txt.gz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved h5ad file: converted_data/GSM2396856_dc_3hr.h5ad\n",
      "✅ Saved h5ad file: converted_data/GSM2396857_dc_0hr.h5ad\n",
      "✅ Saved h5ad file: converted_data/GSM2396858_k562_tfs_7.h5ad\n",
      "✅ Saved h5ad file: converted_data/GSM2396859_k562_tfs_13.h5ad\n",
      "✅ Saved h5ad file: converted_data/GSM2396860_k562_tfs_highmoi.h5ad\n",
      "✅ Saved h5ad file: converted_data/GSM2396861_k562_ccycle.h5ad\n",
      "✅ All datasets processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scanpy as sc\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define folders\n",
    "data_folder = \"extracted_data/\"\n",
    "output_folder = \"converted_data/\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"✅ Created directory: {output_folder}\")\n",
    "\n",
    "# Get all `.mtx` files (expression matrices)\n",
    "mtx_files = glob.glob(os.path.join(data_folder, \"*.mtx.txt.gz\"))\n",
    "\n",
    "# Process each dataset\n",
    "for mtx_file in mtx_files:\n",
    "    try:\n",
    "       \n",
    "        base_name = os.path.basename(mtx_file).split(\".mtx\")[0]\n",
    "\n",
    "        # Find all associated metadata files\n",
    "        metadata_files = glob.glob(os.path.join(data_folder, f\"{base_name}_*.csv.gz\"))\n",
    "\n",
    "        # Load sparse gene expression matrix\n",
    "        matrix = scipy.io.mmread(mtx_file).tocsc()\n",
    "\n",
    "        # Dictionary to store metadata tables\n",
    "        metadata_dict = {}\n",
    "\n",
    "        # Load metadata dynamically and check lengths\n",
    "        for meta_file in metadata_files:\n",
    "            meta_df = pd.read_csv(meta_file)\n",
    "\n",
    "            # Check number of rows\n",
    "            meta_length = meta_df.shape[0]\n",
    "\n",
    "            # Store metadata in dictionary\n",
    "            metadata_dict[meta_length] = metadata_dict.get(meta_length, []) + [meta_df]\n",
    "\n",
    "        # Merge metadata based on row counts\n",
    "        genes_metadata = pd.concat(metadata_dict.get(matrix.shape[0], []), axis=1) if matrix.shape[0] in metadata_dict else None\n",
    "        cells_metadata = pd.concat(metadata_dict.get(matrix.shape[1], []), axis=1) if matrix.shape[1] in metadata_dict else None\n",
    "\n",
    "        # Convert to AnnData format\n",
    "        adata = sc.AnnData(X=matrix.T)  \n",
    "        \n",
    "        if genes_metadata is not None:\n",
    "            adata.var = genes_metadata\n",
    "        if cells_metadata is not None:\n",
    "            adata.obs = cells_metadata\n",
    "\n",
    "        # Save to h5ad format\n",
    "        h5ad_path = os.path.join(output_folder, f\"{base_name}.h5ad\")\n",
    "        adata.write(h5ad_path)\n",
    "        print(f\"Saved h5ad file: {h5ad_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {mtx_file}: {e}\")\n",
    "\n",
    "print(\"All datasets processed successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAACATACATGTGC_cc7d_D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAACATACATTCCT_cc7d_D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAACATACCCCGTT_cc7d_D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAACATACGATAGA_cc7d_D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAACATACGTACGT_cc7d_D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25966</th>\n",
       "      <td>25966</td>\n",
       "      <td>TTTGCATGGCCATA_cc7d_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25967</th>\n",
       "      <td>25967</td>\n",
       "      <td>TTTGCATGGCTAAC_cc7d_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25968</th>\n",
       "      <td>25968</td>\n",
       "      <td>TTTGCATGGCTACA_cc7d_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25969</th>\n",
       "      <td>25969</td>\n",
       "      <td>TTTGCATGTAGAGA_cc7d_C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25970</th>\n",
       "      <td>25970</td>\n",
       "      <td>TTTGCATGTGTAGC_cc7d_C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25971 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                       0\n",
       "0               0  AAACATACATGTGC_cc7d_D2\n",
       "1               1  AAACATACATTCCT_cc7d_D2\n",
       "2               2  AAACATACCCCGTT_cc7d_D2\n",
       "3               3  AAACATACGATAGA_cc7d_D2\n",
       "4               4  AAACATACGTACGT_cc7d_D2\n",
       "...           ...                     ...\n",
       "25966       25966  TTTGCATGGCCATA_cc7d_C1\n",
       "25967       25967  TTTGCATGGCTAAC_cc7d_C1\n",
       "25968       25968  TTTGCATGGCTACA_cc7d_C1\n",
       "25969       25969  TTTGCATGTAGAGA_cc7d_C1\n",
       "25970       25970  TTTGCATGTGTAGC_cc7d_C1\n",
       "\n",
       "[25971 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\nlp\\Lib\\site-packages\\anndata\\_core\\aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "d:\\anaconda\\envs\\nlp\\Lib\\site-packages\\anndata\\_core\\aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]]\n",
      "       Unnamed: 0                          0\n",
      "0               0  AAACATACACGTAC_dc3hLPS_A8\n",
      "1               1  AAACATACATGTCG_dc3hLPS_A8\n",
      "2               2  AAACATACCAACTG_dc3hLPS_A8\n",
      "3               3  AAACATACTCCTTA_dc3hLPS_A8\n",
      "4               4  AAACATACTCTCCG_dc3hLPS_A8\n",
      "...           ...                        ...\n",
      "32772       32772  TTTCTACTGACGAG_dc3hLPS_D9\n",
      "32773       32773  TTTCTACTTCTTAC_dc3hLPS_D9\n",
      "32774       32774  TTTGACTGAAAAGC_dc3hLPS_D9\n",
      "32775       32775  TTTGCATGCGACAT_dc3hLPS_D9\n",
      "32776       32776  TTTGCATGCTGAGT_dc3hLPS_D9\n",
      "\n",
      "[32777 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\converted_data\\GSM2396856_dc_3hr.h5ad\"\n",
    "\n",
    "# Load the data\n",
    "adata = sc.read_h5ad(file_path)\n",
    "\n",
    "# Print dataset summary\n",
    "print(adata.X.toarray())\n",
    "print(adata.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gene_preprocessing\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[0;32m      5\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(methods\u001b[38;5;241m.\u001b[39mpreprocessing)  \u001b[38;5;66;03m# Force reload the module\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:701\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'methods'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from methods.preprocessing import gene_preprocessing\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "importlib.reload(methods.preprocessing)  \n",
    "\n",
    "\n",
    "def merge_perturbed_genes(original_adata, preprocessed_adata, perturbation_names):\n",
    "    \"\"\"\n",
    "    Ensures that missing perturbed genes are added back to the preprocessed AnnData \n",
    "    while avoiding duplication of already-existing genes.\n",
    "\n",
    "    Parameters:\n",
    "    - original_adata: AnnData (before preprocessing)\n",
    "    - preprocessed_adata: AnnData (after preprocessing)\n",
    "    - perturbation_names: List of perturbed gene names (e.g., ['m_Rel_3', 'm_Nfkb1_2'])\n",
    "\n",
    "    Returns:\n",
    "    - Merged AnnData containing missing perturbed genes.\n",
    "    \"\"\"\n",
    "\n",
    "    original_adata.var[\"symbols\"] = original_adata.var[\"0\"].str.split(\"_\").str[-1]\n",
    "\n",
    "    # Extract gene symbols from preprocessed AnnData (genes already kept)\n",
    "    preprocessed_adata.var[\"symbols\"] = preprocessed_adata.var[\"0\"].str.split(\"_\").str[-1]\n",
    "\n",
    "    # Clean perturbed gene names (e.g., \"m_Rel_3\" → \"Rel\")\n",
    "    cleaned_perturbation_genes = [gene.split(\"_\")[1] for gene in perturbation_names if gene != \"control\"]\n",
    "\n",
    "    # Match cleaned perturbation names to original gene symbols\n",
    "    matched_genes = {}\n",
    "    for gene in cleaned_perturbation_genes:\n",
    "        match, score = process.extractOne(gene, original_adata.var[\"symbols\"].values)\n",
    "        if score > 85 and gene.lower() in match.lower():\n",
    "            matched_genes[gene] = match\n",
    "\n",
    "    print(\"Matched Genes:\", matched_genes)\n",
    "\n",
    "    # Identify which matched genes are **already in preprocessed_adata**\n",
    "    existing_genes = preprocessed_adata.var[\"symbols\"].tolist()\n",
    "    missing_genes = [gene for gene in matched_genes.values() if gene not in existing_genes]\n",
    "\n",
    "    # Get indices of missing genes in original AnnData\n",
    "    missing_indices = original_adata.var.index[original_adata.var[\"symbols\"].isin(missing_genes)].tolist()\n",
    "\n",
    "    if not missing_indices:\n",
    "        print(\"No missing perturbed genes to recover. Returning preprocessed AnnData.\")\n",
    "        return preprocessed_adata\n",
    "\n",
    "    # Extract missing genes' data from original AnnData\n",
    "    adding_X = original_adata[:, missing_indices].X\n",
    "    adding_var = original_adata.var.loc[missing_indices]\n",
    "\n",
    "    # Merge missing genes into preprocessed_adata\n",
    "    new_X = np.hstack((preprocessed_adata.X, adding_X))  # Append columns to AnnData.X\n",
    "    new_var = pd.concat([preprocessed_adata.var, adding_var])  # Append rows to AnnData.var\n",
    "\n",
    "    # Create new merged AnnData\n",
    "    merged_adata = sc.AnnData(X=new_X, obs=preprocessed_adata.obs.copy(), var=new_var.copy())\n",
    "\n",
    "    print(f\"Recovered {len(missing_indices)} missing perturbed genes and merged them back.\")\n",
    "\n",
    "    return merged_adata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "perturbation_path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\extracted_data\\GSM2396856_dc_3hr_cbc_gbc_dict_strict.csv.gz\"\n",
    "df_perturbations = pd.read_csv(perturbation_path, header=None)  # Read compressed CSV\n",
    "df_perturbations.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "perturbation_names = df_perturbations[0]\n",
    "\n",
    "adata_prep = gene_preprocessing(adata, num=5000, log_transform=True, normalize=True, select_by=\"random\")\n",
    "adata_prep.obs\n",
    "adata_merge = merge_perturbed_genes(adata, adata_prep, perturbation_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAACATACACGTAC_dc3hLPS_A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAACATACATGTCG_dc3hLPS_A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAACATACCAACTG_dc3hLPS_A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAACATACTCCTTA_dc3hLPS_A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAACATACTCTCCG_dc3hLPS_A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32772</th>\n",
       "      <td>32772</td>\n",
       "      <td>TTTCTACTGACGAG_dc3hLPS_D9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32773</th>\n",
       "      <td>32773</td>\n",
       "      <td>TTTCTACTTCTTAC_dc3hLPS_D9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32774</th>\n",
       "      <td>32774</td>\n",
       "      <td>TTTGACTGAAAAGC_dc3hLPS_D9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32775</th>\n",
       "      <td>32775</td>\n",
       "      <td>TTTGCATGCGACAT_dc3hLPS_D9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32776</th>\n",
       "      <td>32776</td>\n",
       "      <td>TTTGCATGCTGAGT_dc3hLPS_D9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32777 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                          0\n",
       "0               0  AAACATACACGTAC_dc3hLPS_A8\n",
       "1               1  AAACATACATGTCG_dc3hLPS_A8\n",
       "2               2  AAACATACCAACTG_dc3hLPS_A8\n",
       "3               3  AAACATACTCCTTA_dc3hLPS_A8\n",
       "4               4  AAACATACTCTCCG_dc3hLPS_A8\n",
       "...           ...                        ...\n",
       "32772       32772  TTTCTACTGACGAG_dc3hLPS_D9\n",
       "32773       32773  TTTCTACTTCTTAC_dc3hLPS_D9\n",
       "32774       32774  TTTGACTGAAAAGC_dc3hLPS_D9\n",
       "32775       32775  TTTGCATGCGACAT_dc3hLPS_D9\n",
       "32776       32776  TTTGCATGCTGAGT_dc3hLPS_D9\n",
       "\n",
       "[32777 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_merge.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAAGCGTGACTCTT_dc3hLPS_D8, TGACGCCTTGGTTG_dc3hLPS_D8, CGACTCTGCTTGTT_dc3hLPS_D8, GACTTTACAAGATG_dc3hLPS_D8, AGCGCCGACTTGGA_dc3hLPS_D8, TCACAACTCCAATG_dc3hLPS_D8, TAACCGGATTCGTT_dc3hLPS_D8, TAAATGTGCTCAAG_dc3hLPS_D8, TGGCAATGACAGCT_dc3hLPS_D8, CTTCACCTTAGACC_dc3hLPS_D8, TGAAATTGTTCATC_dc3hLPS_D8, AGACTGACAGAGTA_dc3hLPS_D8, CGAAGTACCCTCCA_dc3hLPS_D8, AAGATTACAAGATG_dc3hLPS_D8, GTCGCACTAAAGCA_dc3hLPS_D8, CAGACTGATGGTTG_dc3hLPS_D8, TCAGTGGACTACTT_dc3hLPS_D8, TCTGATACCTAGCA_dc3hLPS_D8, ATCCTAACCTTGTT_dc3hLPS_D8, TGTAATGACCATAG_dc3hLPS_D8, CTAGGCCTGAATCC_dc3hLPS_D8, TTATTCCTAGTAGA_dc3hLPS_D8, CTCGAAGATGGATC_dc3hLPS_D8, ATCAGGTGCACACA_dc3hLPS_D8, CATTACACTGGTTG_dc3hLPS_D8, CACTCTCTCCTTTA_dc3hLPS_D8, AGGGACGATGTGGT_dc3hLPS_D8, AGGACACTAAGTAG_dc3hLPS_D8, AGCGAACTTGGTGT_dc3hLPS_D8, ATGTACCTGATAGA_dc3hLPS_D8, ACGATGACCCCGTT_dc3hLPS_D8, TTGCTAACCGTTAG_dc3hLPS_D8, CTTCTAGACATGGT_dc3hLPS_D8, TGAGACACGCTAAC_dc3hLPS_D8, AGAGTCTGGGACTT_dc3hLPS_B9, CCCAACACATAAGG_dc3hLPS_B9, ACCTGGCTGACGAG_dc3hLPS_B9, TGGTCAGATCTATC_dc3hLPS_B9, AGAGAATGTGAGGG_dc3hLPS_B9, CTTCTAGACACCAA_dc3hLPS_B9, TGTTAAGAACTGGT_dc3hLPS_B9, GCAGCGTGAAAGTG_dc3hLPS_B9, ATCATCTGGGTGTT_dc3hLPS_B9, CTTACTGAAAAGCA_dc3hLPS_B9, CGTACCTGTTCTGT_dc3hLPS_B9, ACTTTGTGGGGCAA_dc3hLPS_B9, TGGAACACATGTGC_dc3hLPS_B9, ACGAACTGAGGCGA_dc3hLPS_B9, GAGGGCCTTGTAGC_dc3hLPS_B9, GGCTAATGACCACA_dc3hLPS_B9, CCGTAAGATTGACG_dc3hLPS_B9, CGCGATCTAAGGTA_dc3hLPS_B9, AAATCATGAGATGA_dc3hLPS_B9, GGGAAGTGTATCTC_dc3hLPS_B9, TGGTTACTGGGACA_dc3hLPS_B8, TCGGTAGACTTCTA_dc3hLPS_B8, AAGGCTACTCCAAG_dc3hLPS_B8, AGATCGTGAGTCGT_dc3hLPS_B8, CACCACTGGTCTTT_dc3hLPS_B8, AGTAGGCTTGATGC_dc3hLPS_B8, TCCCTACTACCGAT_dc3hLPS_B8, CACGGGTGTTCTGT_dc3hLPS_B8, TGGATCGATTGTGG_dc3hLPS_B8, CACGAAACACACAC_dc3hLPS_B8, TGCCCAACTATCGG_dc3hLPS_B8, GAGGGCCTGTTAGC_dc3hLPS_B8, CGGGACTGAGCTCA_dc3hLPS_B8, AAACTTGACGTTAG_dc3hLPS_B8, ATCGCCTGGTCTTT_dc3hLPS_B8, TGACCAGACCAACA_dc3hLPS_B8, CTTTACGACTTATC_dc3hLPS_B8, TAAGGCTGCAGAAA_dc3hLPS_B8, CAAGCTGAAAGAAC_dc3hLPS_B8, GATGCATGCCGATA_dc3hLPS_B8, TCGAGCCTCTGTGA_dc3hLPS_B8, GACTACGAGGGCAA_dc3hLPS_B8, CCGAAAACACACTG_dc3hLPS_B8, GAAACAGACAACCA_dc3hLPS_B8, CTGCAGCTCTCGAA_dc3hLPS_B8, CATGCCACTTGTCT_dc3hLPS_B8, AGTCGCCTGCGTTA_dc3hLPS_B8, TATACAGATAACCG_dc3hLPS_B8, TGCAATCTTTATCC_dc3hLPS_B8, TAGGTGTGAAGGTA_dc3hLPS_B8, GAGGTACTAGTACC_dc3hLPS_B8, AATGAGGATGTCAG_dc3hLPS_A8, GAGGTGGATTTGGG_dc3hLPS_A8, CGCAACCTGCTAAC_dc3hLPS_A8, CAATGGACAGTAGA_dc3hLPS_A8, CCTTTAGAGTATCG_dc3hLPS_A8, TAATGAACATCGAC_dc3hLPS_A8, ACGAGGGAGTCATG_dc3hLPS_A8, CGCTACACGCTTAG_dc3hLPS_A8, CATAAATGCTATGG_dc3hLPS_A8, CTCGAAGAGGTACT_dc3hLPS_A8, CTATGACTGTTCGA_dc3hLPS_A8, AAGTTATGAAGGCG_dc3hLPS_A8, AACGCAACCTGTAG_dc3hLPS_A8, TACCGGCTTCCCAC_dc3hLPS_A8, TCCACGTGTAGTCG_dc3hLPS_A8, TAAACAACCTGTGA_dc3hLPS_A8, GACGATTGAACAGA_dc3hLPS_A8, ACAACCGACGTTGA_dc3hLPS_A8, GGGATTACTAGCCA_dc3hLPS_A8, AGAGAATGTTGAGC_dc3hLPS_A8, TCAGAGACCTATGG_dc3hLPS_A8, GGGAACGACTCGCT_dc3hLPS_A8, ATAGATTGCCGTAA_dc3hLPS_A8, CAGCCTTGCGCCTT_dc3hLPS_A8, ATTAACGAATCGTG_dc3hLPS_A8, CGATCCACCGATAC_dc3hLPS_A8, CTGGAAACTTACCT_dc3hLPS_A8, TTGATCTGCCAGTA_dc3hLPS_A8, CAGATCGAGTTGGT_dc3hLPS_A8, ACGAGGGAACTGTG_dc3hLPS_A8, GTGGAGGATGCTAG_dc3hLPS_A8, ATTGCACTAACCGT_dc3hLPS_A8, GTAAGCACCAGAGG_dc3hLPS_A8, TATGGTCTCTGACA_dc3hLPS_A8, CACTTAACTACGCA_dc3hLPS_A8, AACATATGCTATGG_dc3hLPS_A8, CGAGCCGATAGCGT_dc3hLPS_A8, TTAGGGACACCAGT_dc3hLPS_A8, ATCTTTCTCAACCA_dc3hLPS_A9, GTGACCCTGGTATC_dc3hLPS_A9, TTCGTATGACCCTC_dc3hLPS_A9, TACATCACAAAACG_dc3hLPS_A9, TTATGGCTTTGACG_dc3hLPS_A9, TGATTAGACAGATC_dc3hLPS_A9, GTCCAGCTCGTTGA_dc3hLPS_A9, ACTGAGACTCTCAT_dc3hLPS_A9, CCTAAGGAGATAGA_dc3hLPS_A9, TACATAGAGAGGAC_dc3hLPS_A9, TTCTACGAATAAGG_dc3hLPS_A9, GACAGTACCCTCGT_dc3hLPS_A9, CAGATCGAGTAGCT_dc3hLPS_A9, GCAAACTGCGAGTT_dc3hLPS_A9, ACAGACACAACCGT_dc3hLPS_A9, GTACAGTGCTCTAT_dc3hLPS_A9, CCCTCAGACCCTCA_dc3hLPS_A9, ACGCACCTGGTGTT_dc3hLPS_A9, GACAGTACATACCG_dc3hLPS_A9, TAGTCGGACCTCAC_dc3hLPS_A9, TGAAGCACCTCATT_dc3hLPS_A9, AAGTAACTTCGACA_dc3hLPS_A9, ACGGTATGGAGGTG_dc3hLPS_A9, ACAGTTCTCTTATC_dc3hLPS_A9, GATCGTGACTTGTT_dc3hLPS_A9, CCACCATGGTCGAT_dc3hLPS_A9, GGAGCCACAGTAGA_dc3hLPS_C8, AAGTGCACGAGAGC_dc3hLPS_C8, CCCACATGTCGATG_dc3hLPS_C8, GGAGGATGCTTGCC_dc3hLPS_C8, TGCAATCTAAGCAA_dc3hLPS_C8, TCGCACTGTAGCGT_dc3hLPS_C8, ACGAACTGTTATCC_dc3hLPS_C8, AATTACGAATTCCT_dc3hLPS_C8, CTGAGCCTAGCGGA_dc3hLPS_C8, GCATTGGACTTGCC_dc3hLPS_C8, CAGCGGACACGTTG_dc3hLPS_C8, CATAAATGAAGAGT_dc3hLPS_C8, TAGCGATGAAGCAA_dc3hLPS_C8, CAAGGTTGACCAGT_dc3hLPS_C8, TATTTCCTTCTATC_dc3hLPS_C8, AGGCAACTGACGTT_dc3hLPS_C8, AACAGCACGTCCTC_dc3hLPS_C8, GGAAGGACCACCAA_dc3hLPS_C8, AATTACGAAACGAA_dc3hLPS_C8, CGCTACTGCTCTTA_dc3hLPS_C8, AAATACTGGTTGAC_dc3hLPS_C8, CGTCAAGAGAGGGT_dc3hLPS_C8, GCATGTGAGAGATA_dc3hLPS_C8, AGTTATGAAGTTCG_dc3hLPS_C8, ATGACGTGATGGTC_dc3hLPS_C8, ACCAGTGAGGTACT_dc3hLPS_C8, GCTCGACTCACCAA_dc3hLPS_C8, AAAGAGACATCGTG_dc3hLPS_C8, ATAGCCGAATTCGG_dc3hLPS_C8, AGACTTCTCGCAAT_dc3hLPS_C8, TGACGCCTCGGAGA_dc3hLPS_C8, ACGTTGGACCCGTT_dc3hLPS_C8, TAACTCACAAAAGC_dc3hLPS_E9, AGACTTCTCTACCC_dc3hLPS_E9, ATGCAGTGTCGTGA_dc3hLPS_E9, TATACCACCGACAT_dc3hLPS_E9, ACCCAGCTTCAAGC_dc3hLPS_E9, GGCCACGAAGAGTA_dc3hLPS_E9, AGCGAACTGCAAGG_dc3hLPS_E9, TAACGTCTCGAATC_dc3hLPS_E9, AGGCTAACGTCGAT_dc3hLPS_E9, TACGTTACCCAGTA_dc3hLPS_E9, CCCTGAACACTGGT_dc3hLPS_E9, GAAGTGCTGTTTCT_dc3hLPS_E9, GCGATATGCAGAGG_dc3hLPS_E9, GTGCTAGAGAGACG_dc3hLPS_E9, ATTAGTGATGGTCA_dc3hLPS_E9, GCAGCCGATTCCCG_dc3hLPS_E9, GAACGGGATTCGGA_dc3hLPS_E9, CTACTCCTGTATGC_dc3hLPS_E9, AGGGTTTGAAGTGA_dc3hLPS_E9, GATCGAACTATGGC_dc3hLPS_E9, ACAACCGAGGGACA_dc3hLPS_E9, AGGAAATGGTCATG_dc3hLPS_E9, CCGGTACTGGAACG_dc3hLPS_E9, TCTCAAACACGGAG_dc3hLPS_E9, GGCGACTGGTCGTA_dc3hLPS_E9, GGGAAGTGCAATCG_dc3hLPS_D9, CCCTCAGATTAGGC_dc3hLPS_D9, ATCTTTCTATTGGC_dc3hLPS_D9, AGACTTCTCAGAAA_dc3hLPS_D9, GCACGGACACCAGT_dc3hLPS_D9, CGCGAGACGCAGAG_dc3hLPS_D9, ACCAGCCTTGCCCT_dc3hLPS_D9, ATTCCATGCTTGAG_dc3hLPS_D9, TTGATCTGACTAGC_dc3hLPS_D9, GCAGGCACGGAACG_dc3hLPS_D9, GTGATGACTGCGTA_dc3hLPS_D9, CAGAGGGATTCGCC_dc3hLPS_D9, CCTATAACTAACGC_dc3hLPS_D9, CTCGAGCTAGTGCT_dc3hLPS_D9, TGGGTATGACCAGT_dc3hLPS_D9, GTAGTGACGAAGGC_dc3hLPS_D9, GCGAAGGATCAGAC_dc3hLPS_D9, ATATAGTGGTGTTG_dc3hLPS_D9, TCATCCCTTAGCCA_dc3hLPS_D9, ATGAAACTATCGGT_dc3hLPS_D9, ACAATCCTCTCTAT_dc3hLPS_D9, GAGTGGGAATCGAC_dc3hLPS_D9, ATTACCACCTAAGC_dc3hLPS_D9, CTGCAGCTTGCAAC_dc3hLPS_D9, ACTCCCGAAGAACA_dc3hLPS_C9, CTGGATGACTGACA_dc3hLPS_C9, CCACCATGTCCAAG_dc3hLPS_C9, CGTACAGATGCAGT_dc3hLPS_C9, GACCATGAGAGGCA_dc3hLPS_C9, GCAGCGTGTTGTGG_dc3hLPS_C9, GACCTCACGTTCTT_dc3hLPS_C9, ACGGCGTGACGGTT_dc3hLPS_C9, CTTTAGTGTCGCAA_dc3hLPS_C9, CTATTGTGCCTTAT_dc3hLPS_C9, AAATGGGAGGAGGT_dc3hLPS_C9, ATAACCCTTCCTGC_dc3hLPS_C9, GATCTACTACTGTG_dc3hLPS_C9, GCGCGATGAAGCAA_dc3hLPS_C9, GATACTCTGTGCAT_dc3hLPS_C9, AATGGAGAGAATGA_dc3hLPS_C9, CACGGGACGAAAGT_dc3hLPS_C9, AGAGTCTGCGTAGT_dc3hLPS_C9, TCAAGTCTACCTGA_dc3hLPS_C9, TTGACACTCGAGAG_dc3hLPS_C9, AGCACAACGCAAGG_dc3hLPS_C9, AGTGTGACCCACCT_dc3hLPS_C9, CTTAACACTCAGGT_dc3hLPS_C9, GCGTAATGGGAGGT_dc3hLPS_C9, CGTGATGAGCTCCT_dc3hLPS_C9, ATGAAACTGTCTAG_dc3hLPS_C9, GGACCTCTAACGTC_dc3hLPS_C9\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\extracted_data\\GSM2396856_dc_3hr_cbc_gbc_dict_strict.csv.gz\"\n",
    "genes = pd.read_csv(path, header=None)\n",
    "genes.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "genes = genes.iloc[1:]\n",
    "# print(genes)\n",
    "print(genes.iloc[0,1])\n",
    "genes[\"cells\"] = genes[\"gene_name\"].apply(lambda x: x.split(\", \"))\n",
    "print(len(genes.iloc[0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _cs_matrix.toarray of <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 52199775 stored elements and shape (32777, 17775)>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X.toarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adata_merge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 44\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Step 4: Convert dictionary to a DataFrame\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# cell_perturb_df = pd.DataFrame(list(cell_to_perturbation.items()), columns=[\"barcode\", \"perturbation\"])\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# cell_perturb_df[\"perturbation\"] = cell_perturb_df[\"perturbation\"].apply(lambda x: \", \".join(x))  # Convert list to string\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# print(f\"Merged perturbation data. Unique perturbations: {adata.obs['perturbation'].nunique()}\")\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m adata1\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43madata_merge\u001b[49m\u001b[38;5;241m.\u001b[39mobs)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[0;32m     46\u001b[0m perturbation_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAssignments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData Science\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrepreduce 1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata_visual\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mextracted_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGSM2396856_dc_3hr_cbc_gbc_dict_strict.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'adata_merge' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_perturbations(adata1, perturbation_path):\n",
    "    \"\"\"\n",
    "    Merges perturbation information into adata.obs based on cell barcodes.\n",
    "\n",
    "    Parameters:\n",
    "    - adata: AnnData object\n",
    "    - perturbation_path: Path to the CSV file containing perturbation data\n",
    "\n",
    "    Returns:\n",
    "    - adata with an added column \"perturbation\" in adata.obs\n",
    "    \"\"\"\n",
    "\n",
    "    #  Load the perturbation file\n",
    "    df_perturbations = pd.read_csv(perturbation_path, header=None)  # Read compressed CSV\n",
    "    df_perturbations.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "    #  Convert cell barcode lists from string to actual lists\n",
    "    df_perturbations[\"Cells\"] = df_perturbations[\"gene_name\"].apply(lambda x: x.split(\", \"))\n",
    "    \n",
    "    #  Create a dictionary mapping each cell barcode to its perturbation(s)\n",
    "    cells = np.array(adata1.obs[\"0\"])\n",
    "    adata1.obs[\"perturbation\"] = \"control\"\n",
    "    for _, row in df_perturbations.iterrows():\n",
    "        perturbed_gene = row[\"Cells\"]\n",
    "        target = row.iloc[0]\n",
    "          # e.g., \"m_Irf1_4\"\n",
    "        for item in perturbed_gene:\n",
    "            if item in cells:\n",
    "                adata1.obs.loc[adata1.obs[\"0\"] == item, \"perturbation\"] = target\n",
    "   \n",
    "    \n",
    "    return adata1\n",
    "\n",
    "print(adata_merge.obs)\n",
    "# Example Usage\n",
    "perturbation_path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\extracted_data\\GSM2396856_dc_3hr_cbc_gbc_dict_strict.csv.gz\"\n",
    "adata_merge = merge_perturbations(adata_merge, perturbation_path)\n",
    "adata_merge.obs[adata_merge.obs[\"perturbation\"]!=\"control\"]\n",
    "adata_merge.write(\"adata_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                 0    gene_symbol\n",
      "16760       16760        ENSMUSG00000097888_Gm26682        Gm26682\n",
      "15760       15760          ENSMUSG00000022867_Usp25          Usp25\n",
      "9677         9677          ENSMUSG00000039431_Mtmr7          Mtmr7\n",
      "4384         4384         ENSMUSG00000035212_Leprot         Leprot\n",
      "14313       14313  ENSMUSG00000021098_4930447C04Rik  4930447C04Rik\n",
      "...           ...                               ...            ...\n",
      "14986       14986           ENSMUSG00000042622_Maff           Maff\n",
      "15812       15812          ENSMUSG00000022952_Runx1          Runx1\n",
      "15830       15830           ENSMUSG00000022895_Ets2           Ets2\n",
      "16882       16882           ENSMUSG00000038418_Egr1           Egr1\n",
      "17251       17251           ENSMUSG00000024927_Rela           Rela\n",
      "\n",
      "[5024 rows x 3 columns]\n",
      "       Unnamed: 0                                 0    gene_symbol  \\\n",
      "16760       16760        ENSMUSG00000097888_Gm26682        Gm26682   \n",
      "15760       15760          ENSMUSG00000022867_Usp25          Usp25   \n",
      "9677         9677          ENSMUSG00000039431_Mtmr7          Mtmr7   \n",
      "4384         4384         ENSMUSG00000035212_Leprot         Leprot   \n",
      "14313       14313  ENSMUSG00000021098_4930447C04Rik  4930447C04Rik   \n",
      "...           ...                               ...            ...   \n",
      "5058         5058       ENSMUSG00000065990_Aurkaip1       Aurkaip1   \n",
      "12870       12870          ENSMUSG00000001507_Itga3          Itga3   \n",
      "8746         8746          ENSMUSG00000019989_Enpp3          Enpp3   \n",
      "9356         9356  ENSMUSG00000047642_D930020B18Rik  D930020B18Rik   \n",
      "6216         6216        ENSMUSG00000085237_Gm15406        Gm15406   \n",
      "\n",
      "             symbols  \n",
      "16760        Gm26682  \n",
      "15760          Usp25  \n",
      "9677           Mtmr7  \n",
      "4384          Leprot  \n",
      "14313  4930447C04Rik  \n",
      "...              ...  \n",
      "5058        Aurkaip1  \n",
      "12870          Itga3  \n",
      "8746           Enpp3  \n",
      "9356   D930020B18Rik  \n",
      "6216         Gm15406  \n",
      "\n",
      "[5000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(adata_merge.var)\n",
    "print(adata_prep.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\W\\AppData\\Local\\Temp\\ipykernel_27804\\1447155994.py:18: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  preprocessed_adata.var[\"symbols\"] = preprocessed_adata.var[\"0\"].str.split(\"_\").str[-1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m perturbation_adata\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Call the function to extract only perturbation genes\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m perturbation_adata \u001b[38;5;241m=\u001b[39m \u001b[43msketch_perturbation_genes\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_prep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbation_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[92], line 26\u001b[0m, in \u001b[0;36msketch_perturbation_genes\u001b[1;34m(preprocessed_adata, perturbation_names)\u001b[0m\n\u001b[0;32m     24\u001b[0m matched_genes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m cleaned_perturbation_genes:\n\u001b[1;32m---> 26\u001b[0m     match, score \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mextractOne(gene, preprocessed_adata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbols\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m85\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gene\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m match\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m     28\u001b[0m         matched_genes[gene] \u001b[38;5;241m=\u001b[39m match\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "\n",
    "def sketch_perturbation_genes(preprocessed_adata, perturbation_names):\n",
    "    \"\"\"\n",
    "    Extracts information only for the perturbation genes from the processed AnnData object.\n",
    "\n",
    "    Parameters:\n",
    "    - preprocessed_adata: AnnData object after preprocessing (5000 most variable genes + perturbed genes).\n",
    "    - perturbation_names: List of perturbation gene names.\n",
    "\n",
    "    Returns:\n",
    "    - perturbation_adata: AnnData object containing only perturbation gene information.\n",
    "    \"\"\"\n",
    "    # Extract gene symbols from the processed AnnData\n",
    "    preprocessed_adata.var[\"symbols\"] = preprocessed_adata.var[\"0\"].str.split(\"_\").str[-1]\n",
    "\n",
    "    # Clean perturbation names (e.g., \"m_Rel_1\" → \"Rel\")\n",
    "    cleaned_perturbation_genes = [gene.split(\"_\")[1] for gene in perturbation_names if gene != \"control\"]\n",
    "\n",
    "    # Match the cleaned perturbed names with gene symbols in preprocessed AnnData\n",
    "    matched_genes = {}\n",
    "    for gene in cleaned_perturbation_genes:\n",
    "        match, score = process.extractOne(gene, preprocessed_adata.var[\"symbols\"].values)\n",
    "        if score > 85 and gene.lower() in match.lower():\n",
    "            matched_genes[gene] = match\n",
    "\n",
    "    print(\"✅ Matched Perturbation Genes:\", matched_genes)\n",
    "\n",
    "    # Get indices of the matched perturbation genes\n",
    "    perturb_indices = preprocessed_adata.var.index[preprocessed_adata.var[\"symbols\"].isin(matched_genes.values())].tolist()\n",
    "\n",
    "    # Extract the perturbation genes' data from preprocessed AnnData\n",
    "    perturbation_adata = preprocessed_adata[:, perturb_indices].copy()\n",
    "\n",
    "    print(f\"✅ Extracted {len(perturb_indices)} perturbation genes from AnnData.\")\n",
    "\n",
    "    return perturbation_adata\n",
    "\n",
    "# Call the function to extract only perturbation genes\n",
    "perturbation_adata = sketch_perturbation_genes(adata, perturbation_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'merge_perturbed_genes_same_size' from 'preprocessing' (c:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\preprocessing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gene_preprocessing, merge_perturbed_genes, merge_perturbed_genes_same_size, sketch_perturbation_genes\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mdata_init\u001b[39;00m():\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_folder, output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, perturbation_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'merge_perturbed_genes_same_size' from 'preprocessing' (c:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\preprocessing.py)"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd \n",
    "import preprocessing\n",
    "import os\n",
    "import glob\n",
    "import scanpy as sc\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from preprocessing import gene_preprocessing, merge_perturbed_genes, merge_perturbed_genes_same_size, sketch_perturbation_genes\n",
    "class data_init():\n",
    "\n",
    "    def __init__(self, data_folder, output_folder = None, perturbation_names = None):\n",
    "        self.data_folder = data_folder\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def base_adata(self, return_cell_type = True):\n",
    "        multi_files = glob.glob(os.path.join(self.data_folder, \"*.mtx.txt.gz\"))\n",
    "        for one_file in multi_files:\n",
    "            try:\n",
    "                base_name = os.path.basename(one_file).split(\".mtx\")[0]  # GMS123456_dc_3hr\n",
    "                genes_path = os.path.join(self.data_folder, f\"{base_name}_genenames.csv.gz\")\n",
    "                cells_path = os.path.join(self.data_folder, f\"{base_name}_cellnames.csv.gz\")\n",
    "                matrix = scipy.io.mmread(one_file).tocsc()  \n",
    "                genes = pd.read_csv(genes_path, header=None)\n",
    "                genes.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "                cells = pd.read_csv(cells_path, header=None)\n",
    "                cells.rename(columns={0: \"cell_barcode\"}, inplace=True)\n",
    "\n",
    "                if genes.shape[0] != matrix.shape[0]:\n",
    "                    genes = genes.iloc[:matrix.shape[0]] \n",
    "\n",
    "                adata = sc.AnnData(X=matrix.T)  \n",
    "                adata.var[\"gene_name\"] = genes[\"gene_name\"].values \n",
    "                adata.obs[\"cell_barcode\"] = cells[\"cell_barcode\"].values  \n",
    "\n",
    "                if self.output_folder != None:\n",
    "                    h5ad_path = os.path.join(self.output_folder, f\"{base_name}.h5ad\")\n",
    "                    adata.write(h5ad_path)\n",
    "                    print(f\"Saved h5ad file: {h5ad_path}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {one_file}: {e}\")\n",
    "        \n",
    "        if return_cell_type == True:\n",
    "            cell_type = base_name.split(\"_\")[1]  \n",
    "            return cell_type\n",
    "\n",
    "    def adata_show(self, data_path):\n",
    "        adata = sc.read_h5ad(data_path)\n",
    "        return adata\n",
    "    \n",
    "    def add_single_perturbation(self, adata, perturbation_path):\n",
    "\n",
    "        df_perturbations = pd.read_csv(perturbation_path, header=None)  # Read compressed CSV\n",
    "        df_perturbations.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "        perturbation_names = df_perturbations[0]\n",
    "\n",
    "        adata_prep = gene_preprocessing(adata, num=5000, log_transform=True, normalize=True, select_by=\"random\")\n",
    "        adata_prep.obs\n",
    "        adata_merge = merge_perturbed_genes(adata, adata_prep, perturbation_names)\n",
    "\n",
    "        return adata_merge\n",
    "    \n",
    "    def add_perturbations(self, adata1, perturbation_path):\n",
    "        \"\"\"\n",
    "        Merges perturbation information into adata.obs based on cell barcodes.\n",
    "\n",
    "        Parameters:\n",
    "        - adata: AnnData object\n",
    "        - perturbation_path: Path to the CSV file containing perturbation data\n",
    "\n",
    "        Returns:\n",
    "        - adata with an added column \"perturbation\" in adata.obs\n",
    "        \"\"\"\n",
    "\n",
    "        # Load the perturbation file\n",
    "        df_perturbations = pd.read_csv(perturbation_path, header=None)  # Read compressed CSV\n",
    "        df_perturbations.rename(columns={1: \"gene_name\"}, inplace=True)\n",
    "        #  Convert cell barcode lists from string to actual lists\n",
    "        df_perturbations[\"Cells\"] = df_perturbations[\"gene_name\"].apply(lambda x: x.split(\", \"))\n",
    "        \n",
    "        #  Create a dictionary mapping each cell barcode to its perturbation(s)\n",
    "        cells = np.array(adata1.obs[\"0\"])\n",
    "        adata1.obs[\"condition\"] = \"control\"\n",
    "        for _, row in df_perturbations.iterrows():\n",
    "            perturbed_gene = row[\"Cells\"]\n",
    "            target = row.iloc[0]\n",
    "            # e.g., \"m_Irf1_4\"\n",
    "            for item in perturbed_gene:\n",
    "                if item in cells:\n",
    "                    adata1.obs.loc[adata1.obs[\"0\"] == item, \"condition\"] = target\n",
    "        \n",
    "        return adata1\n",
    "    \n",
    "\n",
    "\n",
    "    def prep(self, file_path, perturbation_path):\n",
    "\n",
    "        cell_name = self.base_adata()\n",
    "        adata = self.adata_show(file_path)\n",
    "        adata1 = self.add_single_perturbation(adata, perturbation_path)\n",
    "\n",
    "        adata1.obs[\"cell_type\"] = cell_name\n",
    "        adata1.obs.index = adata1.obs[\"0\"]\n",
    "        adata1 = self.add_perturbations(adata1, perturbation_path)\n",
    "        del adata1.obs[\"Unnamed: 0\"]\n",
    "        adata1.var[\"gene_names\"] = adata1.var[\"symbols\"]\n",
    "        del adata1.var[\"Unnamed: 0\"]\n",
    "        del adata1.var[\"0\"]\n",
    "        del adata1.var[\"symbols\"]\n",
    "        # print(\"AnnData.X\",adata1.X)\n",
    "        # print(\"AnnData.obs\",adata1.obs)\n",
    "        # print(\"AnnData.var\",adata1.var)\n",
    "        return adata1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data_folder = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\extracted_data/\"\n",
    "    output_folder = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\converted_data/\"\n",
    "    model = data_init(data_folder, output_folder = output_folder)\n",
    "    cell_name = model.base_adata()\n",
    "    file_path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\converted_data\\GSM2396856_dc_3hr.h5ad\"\n",
    "    adata = model.adata_show(file_path)\n",
    "    \n",
    "    perturbation_path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\extracted_data\\GSM2396856_dc_3hr_cbc_gbc_dict_strict.csv.gz\"\n",
    "    adata1 = model.add_single_perturbation(adata, perturbation_path)\n",
    "    adata1.obs[\"cell_type\"] = cell_name\n",
    "    adata1.obs.index = adata1.obs[\"0\"]\n",
    "    adata1 = model.add_perturbations(adata1, perturbation_path)\n",
    "    del adata1.obs[\"Unnamed: 0\"]\n",
    "    adata1.var[\"gene_names\"] = adata1.var[\"symbols\"]\n",
    "    del adata1.var[\"Unnamed: 0\"]\n",
    "    del adata1.var[\"0\"]\n",
    "    del adata1.var[\"symbols\"]\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"AnnData.X\",adata1.X)\n",
    "    print(\"AnnData.obs\",adata1.obs)\n",
    "    print(\"AnnData.var\",adata1.var)\n",
    "\n",
    "    \n",
    "    data_folder = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\extracted2/\"\n",
    "    output_folder = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\converted_data/\"\n",
    "    file_path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\converted_data\\GSM2396858_k562_tfs_7.h5ad\"\n",
    "    perturbation_path = r\"C:\\Users\\W\\Desktop\\Assignments\\Data Science\\project\\repreduce 1\\data_visual\\extracted2\\GSM2396858_k562_tfs_7_cbc_gbc_dict.csv.gz\"\n",
    "    \n",
    "    model2 = data_init(data_folder, output_folder = output_folder)\n",
    "    adata2 = model2.prep(file_path, perturbation_path)\n",
    "    print(adata2.X.shape, adata1.X.shape)\n",
    "\n",
    "    adata1.write(\"adata1.h5ad\")\n",
    "    adata2.write(\"adata2.h5ad\")\n",
    "\n",
    "\n",
    "    print(\"AnnData.X\",merged_adata.X)\n",
    "    print(\"AnnData.obs\",merged_adata.obs)\n",
    "    print(\"AnnData.var\",merged_adata.var)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
